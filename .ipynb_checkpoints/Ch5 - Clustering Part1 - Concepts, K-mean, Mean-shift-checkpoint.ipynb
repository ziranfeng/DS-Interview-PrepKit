{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "A cluster is a subset of data which are similar. Clustering (also called **unsupervised learning**) is the process of dividing a dataset into groups such that the members of each group are as similar (close) as possible to one another, and different groups are as dissimilar (far) as possible from one another. \n",
    "\n",
    "Clustering can uncover **previously undetected relationships** in a dataset. There are many applications for cluster analysis. For example, in business, cluster analysis can be used to discover and characterize customer segments for marketing purposes and in biology, it can be used for classification of plants and animals given their features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Methods :\n",
    "\n",
    "\n",
    "1. Density-Based Methods :\n",
    "    - These methods consider the clusters as the dense region having some similarity and different from the lower dense region of the space. These methods have good accuracy and ability to merge two clusters.\n",
    "    - Example DBSCAN (Density-Based Spatial Clustering of Applications with Noise) , OPTICS (Ordering Points to Identify Clustering Structure) etc.\n",
    "\n",
    "2. Hierarchical Based Methods :\n",
    "    - The clusters formed in this method forms a tree type structure based on the hierarchy. New clusters are formed using the previously formed one. It is divided into two category\n",
    "            -> Agglomerative (bottom up approach)\n",
    "            -> Divisive (top down approach)\n",
    "    - Examples CURE (Clustering Using Representatives), BIRCH (Balanced Iterative Reducing Clustering and using Hierarchies) etc.\n",
    "\n",
    "3. Partitioning Methods :\n",
    "    - These methods partition the objects into k clusters and each partition forms one cluster. This method is used to optimize an objective criterion similarity function such as when the distance is a major parameter.\n",
    "    - Example: K-means, CLARANS (Clustering Large Applications based upon randomized Search) etc.\n",
    "\n",
    "4. Grid-based Methods :\n",
    "    - In this method the data space are formulated into a finite number of cells that form a grid-like structure. All the clustering operation done on these grids are fast and independent of the number of data objects \n",
    "    - Example STING (Statistical Information Grid), wave cluster, CLIQUE (CLustering In Quest) etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good clustering method requirements are:\t\t\n",
    "- The ability to discover some or all of the hidden clusters.\n",
    "- Within-cluster similarity and between-cluster dissimilarity.\n",
    "- Ability to deal with various types of attributes.\n",
    "- Can deal with noise and outliers.\n",
    "- Can handle high dimensionality.\n",
    "- Scalable, Interpretable and usable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important issue in clustering is how to determine the similarity between two objects, so that clusters can be formed from objects with high similarity within clusters and low similarity between clusters. Commonly, to measure similarity or dissimilarity between objects, a distance measure such as Euclidean, Manhattan and Minkowski is used. A distance function returns a lower value for pairs of objects that are more similar to one another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/Clustering_distance.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-mean clustering and python implenmentation\n",
    "\n",
    "K-Means falls under the category of centroid-based clustering. A centroid is a data point (imaginary or real) at the center of a cluster. In centroid-based clustering, clusters are represented by a central vector or a centroid. This centroid might not necessarily be a member of the dataset. Centroid-based clustering is an iterative algorithm in which the notion of similarity is derived by how close a data point is to the centroid of the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm\t\t\n",
    "1. Clusters the data into k groups where k  is predefined.\n",
    "2. Select k points at random as cluster centers.\n",
    "3. Assign objects to their closest cluster center according to the Euclidean distance function.\n",
    "4. Calculate the centroid or mean of all objects in each cluster.\n",
    "5. Repeat steps 2, 3 and 4 until the same points are assigned to each cluster in consecutive rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train and test datasets to create two DataFrames\n",
    "\n",
    "train_url = \"http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/train.csv\"\n",
    "train = pd.read_csv(train_url)\n",
    "test_url = \"http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/test.csv\"\n",
    "test = pd.read_csv(test_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Train_Set *****\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "\n",
      "\n",
      "***** Test_Set *****\n",
      "   PassengerId  Pclass                                          Name     Sex  \\\n",
      "0          892       3                              Kelly, Mr. James    male   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
      "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
      "3          895       3                              Wirz, Mr. Albert    male   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
      "\n",
      "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
      "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
      "1  47.0      1      0   363272   7.0000   NaN        S  \n",
      "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
      "3  27.0      0      0   315154   8.6625   NaN        S  \n",
      "4  22.0      1      1  3101298  12.2875   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "print(\"***** Train_Set *****\")\n",
    "print(train.head())\n",
    "print(\"\\n\")\n",
    "print(\"***** Test_Set *****\")\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Train_Set *****\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "\n",
      "\n",
      "***** Test_Set *****\n",
      "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
      "count   418.000000  418.000000  332.000000  418.000000  418.000000  417.000000\n",
      "mean   1100.500000    2.265550   30.272590    0.447368    0.392344   35.627188\n",
      "std     120.810458    0.841838   14.181209    0.896760    0.981429   55.907576\n",
      "min     892.000000    1.000000    0.170000    0.000000    0.000000    0.000000\n",
      "25%     996.250000    1.000000   21.000000    0.000000    0.000000    7.895800\n",
      "50%    1100.500000    3.000000   27.000000    0.000000    0.000000   14.454200\n",
      "75%    1204.750000    3.000000   39.000000    1.000000    0.000000   31.500000\n",
      "max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.329200\n"
     ]
    }
   ],
   "source": [
    "print(\"***** Train_Set *****\")\n",
    "print(train.describe())\n",
    "print(\"\\n\")\n",
    "print(\"***** Test_Set *****\")\n",
    "print(test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PassengerId' 'Survived' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch'\n",
      " 'Ticket' 'Fare' 'Cabin' 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "print(train.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very important to note that not all machine learning algorithms support missing values in the data that you are feeding to them. K-Means being one of them. So we need to handle the missing values present in the data. Let's first see where are the values missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass   Name    Sex    Age  SibSp  Parch  Ticket   Fare  \\\n",
       "0        False   False  False  False  False  False  False   False  False   \n",
       "1        False   False  False  False  False  False  False   False  False   \n",
       "2        False   False  False  False  False  False  False   False  False   \n",
       "3        False   False  False  False  False  False  False   False  False   \n",
       "4        False   False  False  False  False  False  False   False  False   \n",
       "\n",
       "   Cabin  Embarked  \n",
       "0   True     False  \n",
       "1   True     False  \n",
       "2   True     False  \n",
       "3   True     False  \n",
       "4   True     False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For the train set\n",
    "train.isna().head()\n",
    "\n",
    "# For the test set\n",
    "test.isna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****In the train set*****\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "*****In the test set*****\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Let's get the total number of missing values in both datasets.\n",
    "print(\"*****In the train set*****\")\n",
    "print(train.isna().sum())\n",
    "print(\"\\n\")\n",
    "print(\"*****In the test set*****\")\n",
    "print(test.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, you can see in the training set, in the columns Age, Cabin and Embarked, there are missing values and in the test set, the Age and Cabin columns contain missing values.\n",
    "\n",
    "There are a couple of ways to handle missing values:\n",
    "\n",
    "- Remove rows with missing values\n",
    "- Impute missing values\n",
    "\n",
    "I prefer the latter one because if you remove the rows with missing values it can cause insufficiency in the data which in turn results in inefficient training of the machine learning model.\n",
    "\n",
    "Now, there are several ways you can perform the imputation:\n",
    "\n",
    "1. A constant value that has meaning within the domain, such as 0, distinct from all other values.\n",
    "2. A value from another randomly selected record.\n",
    "3. A mean, median or mode value for the column.\n",
    "4. A value estimated by another machine learning model.\n",
    "\n",
    "Any imputation performed on the train set will have to be performed on test data in the future when predictions are needed from the final machine learning model. This needs to be taken into consideration when choosing how to impute the missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas provides the fillna() function for replacing missing values with a specific value. Let's apply that with Mean Imputation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values with mean column values in the train set\n",
    "train.fillna(train.mean(), inplace=True)\n",
    "\n",
    "# Fill missing values with mean column values in the test set\n",
    "test.fillna(test.mean(), inplace=True)\n",
    "\n",
    "print(train.isna().sum())\n",
    "print('\\n')\n",
    "print(test.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, you can see there are still some missing values in the Cabin and Embarked columns. This is because these values are non-numeric. In order to perform the imputation the values need to be in numeric form. There are ways to convert a non-numeric value to a numeric one. More on this later.\n",
    "\n",
    "Let's do some more analytics in order to understand the data better. Understanding is really required in order to perform any Machine Learning task. Let's start with finding out which features are categorical and which are numerical.\n",
    "\n",
    "Categorical: Survived, Sex, and Embarked. Ordinal: Pclass.\n",
    "Continuous: Age, Fare. Discrete: SibSp, Parch.\n",
    "Two features are left out which are not listed above in any of the categories. Yes, you guessed it right, Ticket and Cabin. Ticket is a mix of numeric and alphanumeric data types. Cabin is alphanumeric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.629630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.472826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.242363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Survived\n",
       "0       1  0.629630\n",
       "1       2  0.472826\n",
       "2       3  0.242363"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Survival count with respect to Pclass:\n",
    "train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>0.742038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>0.188908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Survived\n",
       "0  female  0.742038\n",
       "1    male  0.188908"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Survival count with respect to Sex:\n",
    "train[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.535885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.464286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.345395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SibSp  Survived\n",
       "1      1  0.535885\n",
       "2      2  0.464286\n",
       "0      0  0.345395\n",
       "3      3  0.250000\n",
       "4      4  0.166667\n",
       "5      5  0.000000\n",
       "6      8  0.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Survival count with respect to SibSp:\n",
    "train[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x105675320>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# \"Age vs. Survived\":\n",
    "g = sns.FacetGrid(train, col='Survived')\n",
    "g.map(plt.hist, 'Age', bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAHUCAYAAABMP5BeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzt3XvUZHV95/v3B1oTbwkiDSKXQU1rBE4g0gEVVw7qoK05I0xGQEYH8EA65JCTaMY4eJgYYuLSjLOC17jCQdLgCtqIEAmLgAyKmijQEC4CCvQggZZLd6ujouZow/f8UbtN8fB0P5eq6qp6fu/XWrWq9q927fruqvrt+tRv76pKVSFJktqy07gLkCRJO54BQJKkBhkAJElqkAFAkqQGGQAkSWqQAUCSpAYZACRJapABYEiSPJrk5iS3Jfl0kqduZ94zk7x9R9a3jTp+OclXk/x/26snyZokR8zSvkeSy5LckuSOJJcPsbZzkuw/hOWclOQjQ1jOIUm+lmR9kg8lyaDL1OSxHy/5fvyeJPcneWTQZS0FBoDh+XFVHVxVBwI/AU4dd0Hz8B3g94D/vsjbvxu4qqoOqqr9gdMXcuMkO2/ruqo6paruWGRdo/AxYDWwojutGm85GhH78dLux38HHDruIiaFAWA0vgz8EkCSE5Lc2qXrT8ycMclvJVnXXf+ZrZ84khzTfQq5JcmXurYDklzffUK5NcmKQYqsqo1VtQ746SIXsSewoW95t3Z1HpHksq3tST6S5KTu8r1J3pXkH4B3JLm+b779kmxdxjVJVib5nST/rW+ek5J8uLv85r7H46+2boiSvCXJXUm+CBy+yHX7mSR7Ar9QVV+t3k9nng8cPehyNfHsx0uoH3frdm1VPTiMZS0FBoAhS7IMeC3wtSQHAGcAr6yqg4Dfn+UmF1fVr3XXfx04uWt/F/Carv31XdupwAer6mBgJX2dtu/+13YdaebphKGuaM9HgY8n+UKSM5I8Z563+5eqenlVvRd4cpLnde3HARfOmPci4Df7po8D1iZ5UXf58O7xeBR4U/dm/Sf0NhhHArMOPyZ5xTYep6/MMvtePP6x3tC1aYmyH8/LtPVjzbBs3AUsIU9JcnN3+cvAx4HfBi6qqs0AVfWdWW53YJI/A3YBng5c2bX/I7AmyYXAxV3bV4EzkuxNb4Nz98yFVdVxw1qhuVTVlV2nX0VvY3lTkgPncdO1fZcvBI4F3kdvQ/C4+qtqU5J7krwEuBt4Ib3H5jTgEGBdervjnwJsBA4DrqmqTdDbkAIvmKX2LwAHz3NVZ9vf759oLE3246XbjzWDAWB4ftwl2J9J7xU91xvFGuDoqrqlG147AqCqTk1yGPAbwM1JDq6qC5Jc17VdmeSUqvr8jPtcS69zzfQXVXX+ItZru7qN4QXABd1w4a8DD/P40aWfn3GzH/ZdXgt8OsnFvcU9cWPYzXMs8A3gkqqq7rE9r6re2T9jkqOZx5tzklcAZ81y1Y+q6mUz2jYAe/dN7w08MNd9aCrZj5duP9YMBoDRuhq4JMlZVfXtJLvO8unhGcCDSZ4EvAn4FkCS51fVdcB1Sf4dsE+SXwTuqaoPdYn9V4DHbTh25CeHJK8Erq2qHyV5BvB84D7gIWD/JD9Hb6PxKuAfZltGVf3PJI8Cf8TjP1H0u5jeEOw/A/+la7sa+Gz32G5Msiu9x/I64INJngV8HzgGuGWW+533J4eqejDJD7pPL9cBJwAfns9ttSTYj5dAP9YTGQBGqKpuT/Ie4Itd57gJOGnGbH9E78X+z8DX6L34Ad6f3sFBoddJbqF3dO6bk/yUXud89yD1JXk2cAPwC8BjSd4K7F9V35/nIg4BPpJkC71PCud0ByPRDXneSm+476Y5lrMWeD/w3NmurKrvJrmjq+36ru2OJP8V+FySnegdAHVaVV2b5Ex6w6wPAv8EbPMo5QX4HXqf8p4C/H13UgPsx0unH6d3IOJ/BJ6aZAO9dT1z0OVOq/QOapa2LckaYE1VXTPmUiQtkv1YM/ktAEmSGmQA0Hz8LXDvuIuQNBD7sR7HXQCSJDXIEQBJkho0Ed8CWLVqVV1xxRXjLkNq0VD+1Mg+LI3NovvwRIwAbN68edwlSBqAfViaPhMRACRJ0o5lAJAkqUEGAEmSGmQAkCSpQQYASZIaZACQJKlBBgBJkhpkAJAkqUEGAEmSGmQAkCSpQQYASZIaZACQJKlBBgBJkhpkAJAkqUEGAEmSGmQAkCSpQQYASZIaZACQJKlBBgBJkhpkAJAkqUEGAEmSGmQAkCSpQQYASZIaZACQJKlBBgBJkhpkAJAkqUEGAEmSGmQAkCSpQXMGgCTnJtmY5La+tl2TXJXk7u78mV17knwoyfoktyZ58SiLlyRJizOfEYA1wKoZbacDV1fVCuDqbhrgtcCK7rQa+NhwypQkScM0ZwCoqi8B35nRfBRwXnf5PODovvbzq+daYJckew6rWEmSNByLPQZgj6p6EKA7371r3wu4v2++DV2bJEmaIMM+CDCztNWsMyark9yQ5IZNmzYNuQxJo2YflqbbYgPAw1uH9rvzjV37BmCfvvn2Bh6YbQFVdXZVrayqlcuXL19kGZLGxT4sTbfFBoBLgRO7yycCn+1rP6H7NsBLgO9t3VUgSZImx7K5ZkjySeAIYLckG4A/Bt4HXJjkZOA+4Jhu9suB1wHrgR8BbxlBzZIkaUBzBoCqOn4bV71qlnkLOG3QoiRJ0mj5S4CSJDXIACBJUoMMAJIkNcgAIElSgwwAkiQ1yAAgSVKDDACSJDXIACBJUoMMAJIkNcgAIElSgwwAkiQ1yAAgSVKDDACSJDXIACBJUoMMAJIkNcgAIElSgwwAkiQ1yAAgSVKDDACSJDXIACBJUoMMAJIkNcgAIElSgwwAkiQ1yAAgSVKDDACSJDXIACBJUoMMAJIkNcgAIElSgwwAkiQ1yAAgSVKDDACSJDXIACBJUoOWDXLjJPcCPwAeBbZU1cokuwJrgf2Ae4Fjq+q7g5UpSZKGaRgjAK+oqoOramU3fTpwdVWtAK7upiVJ0gQZxS6Ao4DzusvnAUeP4D4kSdIABg0ABXwuyY1JVndte1TVgwDd+e4D3ockSRqygY4BAA6vqgeS7A5cleQb871hFxhWA+y7774DliFpR7MPS9NtoBGAqnqgO98IXAIcCjycZE+A7nzjNm57dlWtrKqVy5cvH6QMSWNgH5am26IDQJKnJXnG1svAq4HbgEuBE7vZTgQ+O2iRkiRpuAbZBbAHcEmSrcu5oKquSLIOuDDJycB9wDGDlylJkoZp0QGgqu4BDpql/dvAqwYpSpIkjZa/BChJUoMMAJIkNcgAIElSgwwAkiQ1yAAgSVKDDACSJDXIACBJUoMMAJIkNcgAIElSgwwAkiQ1yAAgSVKDDACSJDXIACBJUoMMAJIkNcgAIElSg5aNuwBJUs9ZV901r/neduQLRlyJWuAIgCRJDTIASJLUIAOAJEkN8hiAJWqufYnuQ5Sml8cKaBgcAZAkqUEGAEmSGmQAkCSpQQYASZIa5EGAkrRIHoynaeYIgCRJDXIEQJKWKEcotD0GAEnS0Bk+Jp8BQJJmmO+b17iWJw2DAUATwV8ulCafQWZpMQBo5NxoSJPNPtomA4A0g6MRklowkgCQZBXwQWBn4Jyqet8o7qdVOyqtz+d+JunNcNrq1Y7nJ93JM+znxD4+f0MPAEl2Bj4KHAlsANYlubSq7hj2fU2SYb35TNsGynoXfz9uqCSN0yhGAA4F1lfVPQBJPgUcBSzpADAfk/RmOUm1zMck1TtJtUwrvyKmUfG1NX+jCAB7Aff3TW8ADhvB/fgpSxJgKNP0mKSAkqoa7gKTY4DXVNUp3fR/Ag6tqv97xnyrgdXd5AuBO+dY9G7A5qEWOz6uy2RqcV02V9WqxdyBfdh1mUAtrsvi+/AIAsBLgTOr6jXd9DsBquq9Ay73hqpaOYQSx851mUyuy2hNYk2L5bpMJtdlYUbxZ0DrgBVJnpvkycAbgUtHcD+SJGmRhn4MQFVtSfK7wJX0vgZ4blXdPuz7kSRJizeS3wGoqsuBy4e82LOHvLxxcl0mk+syWpNY02K5LpPJdVmAoR8DIEmSJt8ojgGQJEkTzgAgSVKDDACSJDXIACBJUoMMAJIkNcgAIElSgwwAkiQ1yAAgSVKDDACSJDXIACBJUoMMAJIkNcgAMCRJHk1yc5Lbknw6yVO3M++ZSd6+I+vbRh1vSnJrd/pKkoO2Md+aJEfM0r5HksuS3JLkjiRD+wOoJOck2X8IyzkpyUeGsJxDknwtyfokH0qSQZepyWM/XvL9+D1J7k/yyKDLWgoMAMPz46o6uKoOBH4CnDrugubhm8D/XlW/AvwpC//3qXcDV1XVQVW1P3D6Qm6cZOdtXVdVp1TVHQusZ5Q+BqwGVnSnVeMtRyNiP17a/fjvgEPHXcSkMACMxpeBXwJIckKXzG9J8omZMyb5rSTruus/s/UTR5Jjuk8htyT5Utd2QJLru08otyZZMUiRVfWVqvpuN3ktsPcCF7EnsKFvebd2dR6R5LK+dfxIkpO6y/cmeVeSfwDekeT6vvn2S7J1GdckWZnkd5L8t755Tkry4e7ym/sej7/auiFK8pYkdyX5InD4AtfpCZLsCfxCVX21en+feT5w9KDL1cSzHy+hftyt27VV9eAwlrUUGACGLMky4LXA15IcAJwBvLKqDgJ+f5abXFxVv9Zd/3Xg5K79XcBruvbXd22nAh+sqoOBlfR12r77X9t1pJmnE+Yo/WTg7xe4uh8FPp7kC0nOSPKced7uX6rq5VX1XuDJSZ7XtR8HXDhj3ouA3+ybPg5Ym+RF3eXDu8fjUeBN3Zv1n9DbYBwJzDr8mOQV23icvjLL7Hvx+Md6Q9emJcp+PC/T1o81w7JxF7CEPCXJzd3lLwMfB34buKiqNgNU1Xdmud2BSf4M2AV4OnBl1/6PwJokFwIXd21fBc5Isje9Dc7dMxdWVccttPAkr6C34Xj5Qm5XVVd2nX4VvY3lTUkOnMdN1/ZdvhA4FngfvQ3B4+qvqk1J7knyEuBu4IX0HpvTgEOAdentjn8KsBE4DLimqjZ167YWeMEstX8BOHieqzrb/v6a5201XezHS7cfawYDwPD8uEuwP5PeK3quN4o1wNFVdUs3vHYEQFWdmuQw4DeAm5McXFUXJLmua7syySlV9fkZ97mWXuea6S+q6vyZjUl+BTgHeG1VfXse6/k43cbwAuCCbrjw14GHefzo0s/PuNkP+y6vBT6d5OLe4p64MezmORb4BnBJVVX32J5XVe+csT5HM483525jedYsV/2oql42o20Djx9W3Rt4YK770FSyHy/dfqyZqsrTEE7AI7O0HQDcBTyrm961Oz8TeHt3eTOwO/Ak4CpgTdf+/L7l3EQv5T4PSNf2AeCtA9a8L7AeeNkc860Bjpil/ZXAU7vLz6A39PlrwD7AvcDPAb9I7yClk7r57gV2m7GcdcAngHf0tV0DrOwuPxO4B/gCcGjXtj+9TxK7b31sgX9Db3/mPwPP6h7TLwMfGcLzuw54Cb3RgL8HXjfu15yn4Z/sx0u7H2/veW7x5AjACFXV7UneA3wxyaP0NgAnzZjtj4Dr6L3Yv0avAwK8vzs4KMDVwC30js59c5KfAg/RO3p3EO+i18H+sht+21JVKxdw+0OAjyTZQu+TwjlVtQ6gG/K8lV7nvmmO5awF3g88d7Yrq+q7Se4A9q+q67u2O5L8V+BzSXYCfgqcVlXXJjmT3jDrg8A/Ads8SnkBfofeBvQp9ALAQvezakrZj5dOP07vQMT/CDw1yQZ663rmoMudVltTqLRNSdbQ+0RzzZhLkbRI9mPN5LcAJElqkAFA8/G39Pb5SZpe9mM9jrsAJElqkCMAkiQ1yAAgSVKDJuJrgKtWraorrrhi3GVILRrKvxrah6WxWXQfnogRgM2bN4+7BEkDsA9L02ciAoAkSdqxDACSJDXIACBJUoMMAJIkNcgAIElSgwwAkiQ1yAAgSVKDDACSJDXIACBJUoMMAJIkNcgAIElSgwwAkiQ1yAAgSVKDDACSJDXIACBJUoMMAJIkNcgAIElSgwwAkiQ1yAAgSVKDDACSJDXIACBJUoMMAJIkNcgAIElSgwwAkiQ1yAAgSVKDDACSJDXIACBJUoPmDABJzk2yMcltfW27Jrkqyd3d+TO79iT5UJL1SW5N8uJRFi9JkhZnPiMAa4BVM9pOB66uqhXA1d00wGuBFd1pNfCx4ZQpSZKGac4AUFVfAr4zo/ko4Lzu8nnA0X3t51fPtcAuSfYcVrGSJGk4FnsMwB5V9SBAd757174XcH/ffBu6NkmSNEGGfRBgZmmrWWdMVie5IckNmzZtGnIZkkbNPixNt8UGgIe3Du135xu79g3APn3z7Q08MNsCqursqlpZVSuXL1++yDIkjYt9WJpuiw0AlwIndpdPBD7b135C922AlwDf27qrQJIkTY5lc82Q5JPAEcBuSTYAfwy8D7gwycnAfcAx3eyXA68D1gM/At4ygpolSdKA5gwAVXX8Nq561SzzFnDaoEVJkqTR8pcAJUlqkAFAkqQGGQAkSWqQAUCSpAYZACRJapABQJKkBhkAJElqkAFAkqQGGQAkSWqQAUCSpAYZACRJapABQJKkBhkAJElqkAFAkqQGGQAkSWqQAUCSpAYZACRJapABQJKkBhkAJElqkAFAkqQGGQAkSWqQAUCSpAYZACRJapABQJKkBi0bdwGSJGlwN9544+7Lli07BziQx3/Afwy4bcuWLacccsghG7c2GgAkSVoCli1bds6zn/3sFy1fvvy7O+20U21tf+yxx7Jp06b9H3rooXOA129tdxeAJElLw4HLly//fv+bP8BOO+1Uy5cv/x69kYF/bd+hpUmSpFHZaeabf98VxYz3fAOAJEkNMgBIktQgA4AkSUvDY4899li2cUXofRvgZwwAkiQtDbdt2rTpF2eGgO5bAL8I3NbfPtDXAJPcC/wAeBTYUlUrk+wKrAX2A+4Fjq2q7w5yP5Ikafu2bNlyykMPPXTOQw89tM3fAeiffxi/A/CKqtrcN306cHVVvS/J6d30fxnC/UiSpG3ofuTn9XPO2BnFLoCjgPO6y+cBR4/gPiRJ0gAGDQAFfC7JjUlWd217VNWDAN357gPehyRJGrJBdwEcXlUPJNkduCrJN+Z7wy4wrAbYd999ByxD0o5mH5am20AjAFX1QHe+EbgEOBR4OMmeAN35xm3c9uyqWllVK5cvXz5IGZLGwD4sTbdFB4AkT0vyjK2XgVfT+4rBpcCJ3WwnAp8dtEhJkjRcg+wC2AO4JMnW5VxQVVckWQdcmORk4D7gmMHLlCRJw7ToAFBV9wAHzdL+beBVgxQlSZJGy18ClCSpQQYASZIaZACQJKlBBgBJkhpkAJAkqUEGAEmSGmQAkCSpQQYASZIaZACQJKlBBgBJkhpkAJAkqUEGAEmSGmQAkCSpQQYASZIaZACQJKlBBgBJkhpkAJAkqUEGAEmSGmQAkCSpQQYASZIaZACQJKlBBgBJkhq0bNwFaPjOuuqubV73tiNfsAMrkSRNKkcAJElqkAFAkqQGGQAkSWqQxwBI0gTY3rE74PE7Gj4DwJSaa2MhSdL2GAAmgEftqyV+0l0cHzcNmwFAkobEN2lNEwOAfsaRCElqhwFgiEaxX37Yy/TYAWnbRv0J3v6nSTKSrwEmWZXkziTrk5w+ivuQJEmLN/QRgCQ7Ax8FjgQ2AOuSXFpVdwz7vrTjuHtAO4r70Rdn0MfNPt6eUewCOBRYX1X3ACT5FHAUYABo0GKGPBe7sVns8Kobt+kyzjeqaR7CH2fthrrJNIoAsBdwf9/0BuCwEdyPJoTHKWha+NpanHEfG2FAGI1RBIDM0lZPmClZDazuJh9Jcuccy90N2DxgbZPCdZkgf/CvF6d+XfrMd12uqKpVi7mDSezDfzD3LMPS4mtlm0b9uC9g+S0+L4vvw1VPeG8eSJKXAmdW1Wu66XcCVNV7B1zuDVW1cggljp3rMplcl9GaxJoWy3WZTK7LwoziWwDrgBVJnpvkycAbgUtHcD+SJGmRhr4LoKq2JPld4EpgZ+Dcqrp92PcjSZIWbyQ/BFRVlwOXD3mxZw95eePkukwm12W0JrGmxXJdJpPrsgBDPwZAkiRNvpH8EqAkSZpsBgBJkhpkAJAkqUEGAEmSGmQAkCSpQQYASZIaZACQJKlBBgBJkhpkAJAkqUEGAEmSGmQAkCSpQQYASZIaZAAYkiSPJrk5yW1JPp3kqduZ98wkb9+R9W2jjqOS3NrVfUOSl29jvmuS7DdL+wu7625O8vUkQ/v3qiSXJ9llCMsZymOdZFWSO5OsT3L6oMvTZLIfL/l+fG6SjUluG3RZS4EBYHh+XFUHV9WBwE+AU8dd0DxcDRxUVQcD/ydwzgJv/yHgrG69XwR8eCE3TrLztq6rqtdV1f9aYD0j0dX5UeC1wP7A8Un2H29VGhH78RLtx501wKpxFzEpDACj8WXglwCSnNCl81uSfGLmjEl+K8m67vrPbP3EkeSY7lPILUm+1LUdkOT6LqnfmmTFIEVW1SP1r/8H/TRgof8NvSewoW95X+vqPCnJR/rW8bIkR3SXH0ny7iTXAf9Pkgv75jsiyd91l+9NsluSP0/yf/XNc2aS/9xd/sPusbs1yZ/0zXNG92n9fwAvXOA6zeZQYH1V3VNVPwE+BRw1hOVqstmPl1Y/pqq+BHxnGMtaCpaNu4ClJskyep8Ur0hyAHAGcHhVbU6y6yw3ubiq/t/utn8GnEwvgb8LeE1VfatvCO1U4INV9TdJngw8IXknWcvsneUvqur8Web/98B7gd2B31jg6p4FfD7JV4DPAX89j7T/NOC2qnpX91jdk+RpVfVD4Dhg7Yz5PwV8APjLbvpYYFWSVwMr6L05B7g0ya8DPwTeCPwqvdf3PwE3ziwiyZuAP5ylvvVV9YYZbXsB9/dNbwAOm2M9NcXsx0uyH2sGA8DwPCXJzd3lLwMfB34buKiqNgNU1WzJ88Bug7EL8HTgyq79H4E1XbK+uGv7KnBGkr3pbXDunrmwqjpuIUVX1SXAJV2n+1Pg3y7gtn+d5Ep6Q2pHAb+d5KA5bvYo8Jnu9luSXAH8uyQX0dtwvWPGfdyUZPckzwGWA9+tqvuS/B7wauCmbtan09uQPAO4pKp+BJDk0m3U/jfA38xzVTPbIuZ5W00X+/HS7ceawQAwPD/u9sH9TJIw9xvFGuDoqrolyUnAEQBVdWqSw+h1ppuTHFxVF3RDbr8BXJnklKr6/Iz7XNAnh62q6ktJnp9kt60buvmoqgeAc4Fz0zuw5kBgC4/fvfTzfZf/paoe7ZteC5xGb1huXVX9YJa7uQh4A/Bsep8koPem/N6q+qv+GZO8lXm8OS/wk8MGYJ++6b2BB+a6D00l+/HS7ceaqao8DeEEPDJL2wHAXcCzuuldu/Mzgbd3lzfTG7Z7EnAVsKZrf37fcm4CDgaeB6Rr+wDw1gFr/qW+5b0Y+NbW6RnzXQPsN0v7KuBJ3eVnAw925y8HvkJv47EP8H3giNkeJ3rDn/cCnwaO7Wu/F9it73H8SvdY7tm1vRq4Dnh6N71X9zi+GLgVeAq9TxF3b32sB3iclgH3AM8FngzcAhww7tecp+Gf7MdLtx/31bQfvd0XY3+9jfvkCMAIVdXtSd4DfDHJo/Q2ACfNmO2P6HWAfwa+Ru/FDvD+7uCg0DvK9xbgdODNSX4KPAS8e8AS/wNwQre8HwPHVddD5unVwAeT/Es3/YdV9VCSh4FvdutzG739d7OqqkeTXEbvcTlxG/PcnuQZwLeq6sGu7XNJXgR8tfcBjUeAN1fVP3Wfnm6m95h+eQHrs60atyT5XXrDujsD51bV7YMuV9PBfrw0+jFAkk/SG53ZLckG4I+r6uPDWPY0ysJeJ2pRkmuAk6rq3jGXImmR7Meaya8BSpLUIAOA5mMNMEk/5iFp4dZgP1YfdwFIktQgRwAkSWrQRHwLYNWqVXXFFVeMuwypRbP9yNGC2YelsVl0H56IEYDNm+f9exWSJpB9WJo+ExEAJEnSjmUAkCSpQQYASZIaZACQJKlBE/EtAC3cWVfdNec8bzvyBTugEknSNHIEQJKkBhkAJElqkAFAkqQGGQAkSWqQAUCSpAYZACRJapABQJKkBhkAJElqkAFAkqQGGQAkSWqQAUCSpAYZACRJapABQJKkBhkAJElqkAFAkqQGGQAkSWqQAUCSpAYZACRJapABQJKkBhkAJElqkAFAkqQGGQAkSWqQAUCSpAbNGQCSnJtkY5Lb+tp2TXJVkru782d27UnyoSTrk9ya5MWjLF6SJC3OfEYA1gCrZrSdDlxdVSuAq7tpgNcCK7rTauBjwylTkiQN05wBoKq+BHxnRvNRwHnd5fOAo/vaz6+ea4Fdkuw5rGIlSdJwLPYYgD2q6kGA7nz3rn0v4P6++TZ0bZIkaYIM+yDAzNJWs86YrE5yQ5IbNm3aNOQyJI2afViabosNAA9vHdrvzjd27RuAffrm2xt4YLYFVNXZVbWyqlYuX758kWVIGhf7sDTdFhsALgVO7C6fCHy2r/2E7tsALwG+t3VXgSRJmhzL5pohySeBI4DdkmwA/hh4H3BhkpOB+4BjutkvB14HrAd+BLxlBDVLkqQBzRkAqur4bVz1qlnmLeC0QYuSJEmj5S8BSpLUIAOAJEkNMgBIktQgA4AkSQ0yAEiS1CADgCRJDTIASJLUIAOAJEkNMgBIktQgA4AkSQ0yAEiS1CADgCRJDTIASJLUIAOAJEkNMgBIktQgA4AkSQ0yAEiS1CADgCRJDTIASJLUIAOAJEkNMgBIktQgA4AkSQ0yAEiS1CADgCRJDTIASJLUIAOAJEkNMgBIktQgA4AkSQ0yAEiS1CADgCRJDTIASJLUIAOAJEkNWjbIjZPcC/wAeBTYUlUrk+wKrAX2A+4Fjq2q7w5WpiRJGqZhjAC8oqoOrqqV3fTpwNVVtQK4upuWJEkTZBS7AI4CzusunwccPYL7kCRJAxg0ABTwuSQ3Jlndte1RVQ8CdOe7D3gfkiRpyAY6BgA4vKoeSLIAKkY3AAAHzklEQVQ7cFWSb8z3hl1gWA2w7777DliGpB3NPixNt4FGAKrqge58I3AJcCjwcJI9Abrzjdu47dlVtbKqVi5fvnyQMiSNgX1Ymm6LDgBJnpbkGVsvA68GbgMuBU7sZjsR+OygRUqSpOEaZBfAHsAlSbYu54KquiLJOuDCJCcD9wHHDF6mJEkapkUHgKq6BzholvZvA68apChJkjRagx4EqAU466q75pznbUe+YAdUImkSzbWNcPugYfKngCVJapABQJKkBhkAJElqkMcADMl89u9LkjQpHAGQJKlBjgBMGEcSJEk7giMAkiQ1yAAgSVKDDACSJDXIACBJUoMMAJIkNcgAIElSgwwAkiQ1yAAgSVKDDACSJDXIACBJUoMMAJIkNcgAIElSg/wzoCVsPn8s9LYjX7ADKpEkTRoDgObFMCFJS4u7ACRJapAjAI2bzyd7SdLS4wiAJEkNMgBIktQgA4AkSQ2aymMAPCJdkqTBTGUAGJb5HgBnmJAkLTVNBwAN1zC/UWDoWprmeo1M+vM+aP1+60aTxAAgaWKMOiD4Biz9KwOAJA2JAUPTxAAgSVNi2nehaLKMJAAkWQV8ENgZOKeq3jeK+9meYSZxU/2O5zc9JGm0hv47AEl2Bj4KvBbYHzg+yf7Dvh9JkrR4oxgBOBRYX1X3ACT5FHAUcMcI7kuaOn79dPEcAt++QUcrW3/8WjOKALAXcH/f9AbgsBHcjxo3ibtm3ICO1yS+JqbJtAcIA+LCjCIAZJa2esJMyWpgdTf5SJI751jubsDmAWubFK7LZBp4Xf5gSIUMYVnzXZcrqmrVYu7APuy6zDTM1/8ibXddJqC+hRh9H656wnvzQJK8FDizql7TTb8ToKreO+Byb6iqlUMocexcl8nkuozWJNa0WK7LZHJdFmYUfwa0DliR5LlJngy8Ebh0BPcjSZIWaei7AKpqS5LfBa6k9zXAc6vq9mHfjyRJWryR/A5AVV0OXD7kxZ495OWNk+symVyX0ZrEmhbLdZlMrssCDP0YAEmSNPlGcQyAJEmacFMRAJKsSnJnkvVJTh93PQuRZJ8kX0jy9SS3J/n9rn3XJFclubs7f+a4a52PJDsnuSnJZd30c5Nc163H2u7Az4mXZJckFyX5RvfcvHSKn5O3da+t25J8MsnPT9rzYh+eHEulD4P9eFATHwCWwE8LbwH+c1W9CHgJcFpX/+nA1VW1Ari6m54Gvw98vW/6z4GzuvX4LnDyWKpauA/S+/7sLwMH0VunqXtOkuwF/B6wsqoOpHfg7RuZoOfFPjxxlkofBvvxYKpqok/AS4Er+6bfCbxz3HUNsD6fBY4E7gT27Nr2BO4cd23zqH1veh3qlcBl9H70aTOwbLbnalJPwC8A36Q7BqavfRqfk62/vLkrvYN6LwNeM0nPi314ck5LpQ93tdqPBzxN/AgAs/+08F5jqmUgSfYDfhW4Dtijqh4E6M53H19l8/YB4B3AY930s4D/VVVbuulpeW6eB2wC/robCj0nydOYwuekqr4F/HfgPuBB4HvAjUzW82IfnhxLpQ+D/Xhg0xAA5vXTwpMuydOBzwBvrarvj7uehUryfwAbq+rG/uZZZp2G52YZ8GLgY1X1q8APmYJhwtl0+zePAp4LPAd4Gr2h9pnG+bxM6+vkcezDE8d+PKBpCAAbgH36pvcGHhhTLYuS5En0Nhx/U1UXd80PJ9mzu35PYOO46punw4HXJ7kX+BS9IcQPALsk2fp7EtPy3GwANlTVdd30RfQ2JNP2nAD8W+CbVbWpqn4KXAy8jMl6XuzDk2Ep9WGwHw9sGgLAVP+0cJIAHwe+XlV/0XfVpcCJ3eUT6e1XnFhV9c6q2ruq9qP3HHy+qt4EfAF4QzfbxK8HQFU9BNyf5IVd06vo/V31VD0nnfuAlyR5avda27ouk/S82IcnwFLqw2A/HopxH/wwzwMkXgfcBfxP4Ixx17PA2l9Ob9jmVuDm7vQ6evvergbu7s53HXetC1inI4DLusvPA64H1gOfBn5u3PXNcx0OBm7onpe/BZ45rc8J8CfAN4DbgE8APzdpz4t9eLJOS6EPd7Xbjwc4+UuAkiQ1aBp2AUiSpCEzAEiS1CADgCRJDTIASJLUIAOAJEkNMgBoTkn+fZJK8svjrkXSwtmHNRsDgObjeOAf6P14iKTpYx/WExgAtF3d758fTu9vKN/Yte2U5C+7/66+LMnlSd7QXXdIki8muTHJlVt/klPSeNiHtS0GAM3laHr/t30X8J0kLwZ+E9gP+N+AU+j9TeXW30v/MPCGqjoEOBd4zziKlvQz9mHNatncs6hxx9P7wxDo/YHI8cCTgE9X1WPAQ0m+0F3/QuBA4Krez1mzM72/tpQ0PvZhzcoAoG1K8ix6/xh2YJKitzEo4JJt3QS4vapeuoNKlLQd9mFtj7sAtD1vAM6vqn9TVftV1T7AN4HNwH/o9iPuQe+PRQDuBJYn+dlwYpIDxlG4JMA+rO0wAGh7jueJnxQ+AzyH3n9x3wb8FXAd8L2q+gm9Dc6fJ7mF3r+mvWzHlStpBvuwtsl/A9SiJHl6VT3SDTFeDxxevf/nljQF7MPyGAAt1mVJdgGeDPypGw5p6tiHG+cIgCRJDfIYAEmSGmQAkCSpQQYASZIaZACQJKlBBgBJkhpkAJAkqUH/P8cbu+n6OWTPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 514.88x475.2 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# see how the Pclass and Survived features are related to eachother with a graph:\n",
    "grid = sns.FacetGrid(train, col='Survived', row='Pclass', size=2.2, aspect=1.6)\n",
    "grid.map(plt.hist, 'Age', alpha=.5, bins=20)\n",
    "grid.add_legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "You can see that not all the feature values are of same type. Some of them are numerical and some of them are not. In order to ease the computation, you will feed all numerical data to the model. Let's see the data types of different features that you have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            891 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before converting them into numeric ones, you might want to do some feature engineering, i.e. features like Name, Ticket, Cabin and Embarked do not have any impact on the survival status of the passengers. Often, it is better to train your model with only significant features than to train it with all the features, including unnecessary ones. It not only helps in efficient modelling, but also the training of the model can happen in much lesser time. Although, feature engineering is a whole field of study itself, I will encourage you to dig it further. But for this tutorial, know that the features Name, Ticket, Cabin and Embarked can be dropped and they will not have significant impact on the training of the K-Means model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['Name','Ticket', 'Cabin','Embarked'], axis=1)\n",
    "test = test.drop(['Name','Ticket', 'Cabin','Embarked'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the dropping part is done let's convert the 'Sex' feature to a numerical one (only 'Sex' is remaining now which is a non-numeric feature). You will do this using a technique called Label Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEncoder = LabelEncoder()\n",
    "labelEncoder.fit(train['Sex'])\n",
    "labelEncoder.fit(test['Sex'])\n",
    "train['Sex'] = labelEncoder.transform(train['Sex'])\n",
    "test['Sex'] = labelEncoder.transform(test['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 8 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Sex            891 non-null int64\n",
      "Age            891 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Fare           891 non-null float64\n",
      "dtypes: float64(2), int64(6)\n",
      "memory usage: 55.8 KB\n"
     ]
    }
   ],
   "source": [
    "# Let's investigate if you have non-numeric data left\n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(train.drop(['Survived'], 1).astype(float))\n",
    "\n",
    "y = np.array(train['Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have not scaled the values of the different features that you are feeding to the model. The features in the dataset contain different ranges of values. So, what happens is a small change in a feature does not affect the other feature. So, it is also important to scale the values of the features to a same range.\n",
    "\n",
    "Let's do that now and for this experiment you are going to take 0 - 1 as the uniform value range across all the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=2) # You want cluster the passenger records into 2: Survived or Not survived\n",
    "\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5084175084175084\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(len(X)):\n",
    "    predict_me = np.array(X[i].astype(float))\n",
    "    predict_me = predict_me.reshape(-1, len(predict_me))\n",
    "    prediction = kmeans.predict(predict_me)\n",
    "    if prediction[0] == y[i]:\n",
    "        correct += 1\n",
    "\n",
    "print(correct/len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disadvantages of K-Means\n",
    "Now that you have a fairly good idea on how K-Means algorithm works let's discuss some its disadvantages.\n",
    "\n",
    "The biggest disadvantage is that K-Means requires you to pre-specify the number of clusters (k). However, for the Titanic dataset, you had some domain knowledge available that told you the number of people who survived in the shipwreck. This might not always be the case with real world datasets. Hierarchical clustering is an alternative approach that does not require a particular choice of clusters. An additional disadvantage of k-means is that it is sensitive to outliers and different results can occur if you change the ordering of the data.\n",
    "\n",
    "K-Means is a lazy learner where generalization of the training data is delayed until a query is made to the system. This means K-Means starts working only when you trigger it to, thus lazy learning methods can construct a different approximation or result to the target function for each encountered query. It is a good method for online learning, but it requires a possibly large amount of memory to store the data, and each request involves starting the identification of a local model from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pros\n",
    "    - Finds cluster centers that minimize condiHonal variance (good representaHon of data)\n",
    "    - Simple and fast*\n",
    "    - Easy to implement \n",
    "- Cons\n",
    "    - Need to choose K\n",
    "    - SensiHve to outliers\n",
    "    - Prone to local minima\n",
    "    - All clusters have the same parameters (e.g., distance measure is non- adapHve)\n",
    "    - *Can be slow: each iteraHon is O(KNd) for N d-dimensional points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean-shift Clustering\n",
    "\n",
    "Meanshift is a clustering algorithm that assigns the datapoints to the clusters iteratively by shifting points towards the mode. The mode can be understood as the highest density of datapoints (in the region, in the context of the Meanshift). As such, it is also known as the mode-seeking algorithm. Meanshift algorithm has applications in the field of image processing and computer vision.\n",
    "\n",
    "Given a set of datapoints, the algorithm iteratively assign each datapoint towards the closest cluster centroid. The direction to the closest cluster centroid is determined by where most of the points nearby are at. So each iteration each data point will move closer to where the most points are at, which is or will lead to the cluster center. When the algorithm stops, each point is assigned to a cluster.\n",
    "\n",
    "Unlike the popular K-Means algorithm, meanshift does not require specifying the number of clusters in advance. The number of clusters is determined by the algorithm with respect to the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithm\n",
    "\n",
    "You will need a few things before you start to run Meanshift on a set of datapoints X:\n",
    "\n",
    "- A function N(x) to determine what are the neighbours of a point x ∈ X. The neighbouring points are the points within a certain distance. **The distance metric is usually Euclidean Distance.**\n",
    "- A kernel K(d) to use in Meanshift. **K is usually a Gaussian Kernel, and d is the distance between two datapoints.**\n",
    "\n",
    "Now, with the above, this is the Meanshift algorithm for a set of datapoints X:\n",
    "\n",
    "1. **For each datapoint x ∈ X, find the neighbouring points N(x) of x.**\n",
    "2. **For each datapoint x ∈ X, calculate the mean shift m(x) from this equation: **\n",
    "<img src=\"files/meanshift1.png\">\n",
    "3. **For each datapoint x ∈ X, update x ← m(x).**\n",
    "4. **Repeat 1. for n_iteations or until the points are almost not moving or not moving.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important piece is calculating the mean shift m(x). The formula in step 2. looks daunting but let’s break it down. Notice the red red encircled parts are essentially the same. Let’s replace that with Wi, so the formula becomes this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/meanshift2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially, the meanshift is just **calculating the weighted average of the affected points w.r.t. to x.** From this perspective, the formula is less mystifying.\n",
    "\n",
    "To summarize: The algorithm finds a set of nearby points that affect a datapoint, then shift it towards where most of the points are, and the closest points have more influence than the further points. Repeat this for all datapoints until nothing changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the kernel, euclidean distance, neighbourhood functions we need first:\n",
    "def euclid_distance(x, xi):\n",
    "    return np.sqrt(np.sum((x - xi)**2))\n",
    "\n",
    "def neighbourhood_points(X, x_centroid, distance = 5):\n",
    "    eligible_X = []\n",
    "    for x in X:\n",
    "        distance_between = euclid_distance(x, x_centroid)\n",
    "        # print('Evaluating: [%s vs %s] yield dist=%.2f' % (x, x_centroid, distance_between))\n",
    "        if distance_between <= distance:\n",
    "            eligible_X.append(x)\n",
    "    return eligible_X\n",
    "\n",
    "def gaussian_kernel(distance, bandwidth):\n",
    "    val = (1/(bandwidth*math.sqrt(2*math.pi))) * np.exp(-0.5*((distance / bandwidth))**2)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'original_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-a6dc035deb9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Next, we will implement Meanshift by translating the algorithm as described above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpast_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'original_X' is not defined"
     ]
    }
   ],
   "source": [
    "# Next, we will implement Meanshift by translating the algorithm as described above.\n",
    "X = np.copy(original_X)\n",
    "\n",
    "past_X = []\n",
    "n_iterations = 5\n",
    "for it in range(n_iterations):\n",
    "    for i, x in enumerate(X):\n",
    "        ### Step 1. For each datapoint x ∈ X, find the neighbouring points N(x) of x.\n",
    "        neighbours = neighbourhood_points(X, x, look_distance)\n",
    "        \n",
    "        ### Step 2. For each datapoint x ∈ X, calculate the mean shift m(x).\n",
    "        numerator = 0\n",
    "        denominator = 0\n",
    "        for neighbour in neighbours:\n",
    "            distance = euclid_distance(neighbour, x)\n",
    "            weight = gaussian_kernel(distance, kernel_bandwidth)\n",
    "            numerator += (weight * neighbour)\n",
    "            denominator += weight\n",
    "        \n",
    "        new_x = numerator / denominator\n",
    "        \n",
    "        ### Step 3. For each datapoint x ∈ X, update x ← m(x).\n",
    "        X[i] = new_x\n",
    "    \n",
    "    past_X.append(np.copy(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means VS Meanshift\n",
    "Meanshift looks very similar to K-Means, they both move the point closer to the cluster centroids. One may wonder: How is this different from K-Means? K-Means is faster in terms of runtime complexity!\n",
    "\n",
    "The key difference is that **Meanshift does not require the user to specify the number of clusters.** In some cases, it is not straightforward to guess the right number of clusters to use. In K-Means, the output may end up having too few clusters or too many clusters to be useful. At the cost of larger time complexity, Meanshift determines the number of clusters suitable to the dataset provided.\n",
    "\n",
    "Another commonly cited difference is that K-Means can only learn circle or ellipsoidal clusters. However, this is **not true.** The reason that Meanshift can learn arbitrary shapes is because **the features are mapped to another higher dimensional feature space through the kernel.** The arbitrary shapes are due to the algorithm finding circle or ellipsoidal clusters in higher dimensional feature space. When the features are mapped back to 1D/2D/3D, the resulting clusters look like strange shapes. This is also the trick as used in Support Vector Machines.\n",
    "\n",
    "A traditional K-means does not use kernels, but Kernel K-means is available. Kernel K-Means is useful if 1) the number of clusters is known or can be reasonably estimated, and 2) dataset needs learning non-ellipsoidal cluster shapes. So, you can enjoy the better runtime complexity of K-Means and learn arbitrary clusters if you can determine the number of clusters to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
