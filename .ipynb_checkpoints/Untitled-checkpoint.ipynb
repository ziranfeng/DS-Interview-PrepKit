{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P-Value\n",
    "\n",
    "Given your Null hypothesis is True, the p-value is the probability of your observed data or sample to reach the extreme case, or will be fall into the extreme range.\n",
    "\n",
    "Informally speaking, the P-value is a measurment of whether your hypothesis is acceptable or not.\n",
    "\n",
    "Does the evidence you collected make the null hypothesis look absurd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Common Terms\n",
    "\n",
    "Type 1 Error: Reject Null hypothesis, but Null hypothesis is True\n",
    "\n",
    "Type 2 Error: Fail to reject Null hypothesis, but Null hypothesis is False\n",
    "\n",
    "Significant level is the probability of a statistocal test, that will rejject Null hypothesis, given Null Hypothesis is True.\n",
    "\n",
    "a(Significant level) = Type 1 Error\n",
    "\n",
    "Power: is the probability of correctly rejecting Null Hypothesis\n",
    "b(Power) = 1- Type 2 Error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Margin of Error\n",
    "\n",
    "MoE is the maxiumn expected difference of the statistical estimation and the true population's parameter;\n",
    "In most of cases, we will qualify the MoE by probability that normally expressed by Confidence Interval;\n",
    "\n",
    "\n",
    "This means:\n",
    "If the test is repeated many times with different samples, the True percentage of a visitor will click the button wil fall into the CI or you can say within the MoE, 90% of the times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias and Variance Trade-off\n",
    "\n",
    "Ideally, a good ML model has Low Bias, which means it can accurately model the true relationship; & has Low Variance, which means it producing consistent predictions accross different data sets.\n",
    "\n",
    "- Bias: occurs when an algorithm has limited flexibility to learn the True Pattern in data\n",
    "\n",
    "- Variance: refers to whether the model has consistent outputs\n",
    "\n",
    "Total Error = Bias^2 + Variance + Irreducible Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting\n",
    "\n",
    "Overfitting happens when the model is too closely to fit the training data. The model is then hard to be generalized for future data.\n",
    "\n",
    "- Low training error\n",
    "- High Variance\n",
    "- Training error much lower than test error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution\n",
    "\n",
    "L1 LASSO:   + lambda||theta||_1\n",
    "\n",
    "L2 RIDGE:   + lambda||theta||_2\n",
    "\n",
    "Elastic Net\n",
    "\n",
    "Bagging/Random Forrest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "#### Assumptions \n",
    "\n",
    "- Linear Relationship: scatter plot\n",
    "- All variable to be multivarate normally distributed: Q-Q plot; transformation(taking log) & remove outliers\n",
    "- No or little multicollinearity: correlation matrix, VIF score >10\n",
    "- No or little autocorrelation: Durbin-Watson Test\n",
    "- Homoscedasticity: Residual plot\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multicollinearity\n",
    "\n",
    "Multicollinearity is a state of very high intercorrelation or inter-association among the independent variables.\n",
    "\n",
    "It is type of the disturbance in the data and if present in the data the statistical inference made about the data may not be reliable\n",
    "\n",
    "Causing Problems:\n",
    "1. The partial regression coefficient due to multicollinearity may not be estimated preciselt. The standard errors are high.\n",
    "2. Results in a change in the sign, as well as the magnitudes of partial coefficients.\n",
    "3. Makes it hard and useless to access the importance of the independent variables.\n",
    "\n",
    "\n",
    "VIF > 10 indicates high multicollinearity\n",
    "\n",
    "1. Ridge regression can be used to solve.\n",
    "2. Center the predictos (Xs)\n",
    "3. Remove those coefficients: If it is too hard to find the variables, use data reduction method(clustering&PCA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Metric\n",
    "\n",
    "In general, ROC and AUC first give us a general idea of how well the classification model performs. Then, they can be helpful on determmine th ebest threshold, or decision rules. Along with the actual business cases.\n",
    "\n",
    "\n",
    "ROC is commonly used to visualize the performance of a binary classification.\n",
    "\n",
    "It plots TPR(True Positive Rate) versus FPR(False Positive Rate) for different decision rules, or threshold.\n",
    "A good threshold will be high on TPR and low on FPR.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
